{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e853e4d",
   "metadata": {},
   "source": [
    "# Web Scraping the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05059a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      folder path
    }
   ],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Correct way to rename the nan column to 'Month'\n",
    "\n",
    "folder = Path(folder_path)\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for files in folder.glob(\"*\"):\n",
    "    print(files)\n",
    "    df = pd.read_csv(files)\n",
    "    df= df.iloc[:, [0, 2, 11, 12]]\n",
    "    df.columns = df.iloc[1]\n",
    "    df = df.rename(columns={np.nan: 'Month'})\n",
    "    df = df.iloc[2:]\n",
    "    \n",
    "    all_dfs.append(df)\n",
    "    \n",
    "\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "#Script to clean data of a month wise upi apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d37c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "# URL of the NPCI UPI Product Statistics page\n",
    "url = 'https://www.npci.org.in/what-we-do/upi/product-statistics'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check for request errors\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table containing the statistics\n",
    "# Note: The actual implementation may vary based on the website's HTML structure\n",
    "table = soup.find('table')\n",
    "\n",
    "# Extract table headers\n",
    "headers = [th.get_text(strip=True) for th in table.find('thead').find_all('th')]\n",
    "\n",
    "# Extract table rows\n",
    "rows = []\n",
    "for tr in table.find('tbody').find_all('tr'):\n",
    "    cells = [td.get_text(strip=True).replace(',', '') for td in tr.find_all('td')]\n",
    "    if cells:\n",
    "        rows.append(cells)\n",
    "\n",
    "# Connect to SQLite database (or create it)\n",
    "conn = sqlite3.connect('upi_statistics.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table with appropriate columns\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS upi_statistics (\n",
    "        month TEXT PRIMARY KEY,\n",
    "        banks INTEGER,\n",
    "        volume_mn REAL,\n",
    "        value_cr REAL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Insert data into the table\n",
    "for row in rows:\n",
    "    # Parse the month, banks, volume, and value\n",
    "    month = row[0]\n",
    "    banks = int(row[1])\n",
    "    volume_mn = float(row[2])\n",
    "    value_cr = float(row[3])\n",
    "    \n",
    "    # Insert or replace the data\n",
    "    cursor.execute('''\n",
    "        INSERT OR REPLACE INTO upi_statistics (month, banks, volume_mn, value_cr)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    ''', (month, banks, volume_mn, value_cr))\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "#Pulling Data from npci "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Jan 2022\n",
      "Saved: Jan_2022.csv\n",
      "Processing: Feb 2022\n",
      "Saved: Feb_2022.csv\n",
      "Processing: Mar 2022\n",
      "Saved: Mar_2022.csv\n",
      "Processing: Apr 2022\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Setup headless Chrome browser\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(service=Service(), options=options)\n",
    "\n",
    "# Create output directory if not exists\n",
    "output_dir = \"upi_apps_monthly_csv\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Open the NPCI UPI statistics page\n",
    "driver.get(\"https://www.npci.org.in/what-we-do/upi/upi-ecosystem-statistics\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# Click \"UPI Apps\" tab using JS\n",
    "try:\n",
    "    upi_apps_tab = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href=\"#innerTabTwoJan22\"]')))\n",
    "    driver.execute_script(\"arguments[0].click();\", upi_apps_tab)\n",
    "except Exception as e:\n",
    "    driver.save_screenshot(\"debug_tab_error.png\")\n",
    "    raise Exception(\"Could not click on UPI Apps tab.\") from e\n",
    "\n",
    "# Wait for dropdown to load\n",
    "try:\n",
    "    dropdown = wait.until(EC.presence_of_element_located((By.ID, \"yearDD\")))\n",
    "    select = Select(dropdown)\n",
    "except Exception as e:\n",
    "    driver.save_screenshot(\"debug_dropdown_error.png\")\n",
    "    raise Exception(\"Dropdown not found.\") from e\n",
    "\n",
    "# Select months from Jan 2022 to Dec 2024\n",
    "target_months = [opt.text.strip() for opt in select.options if any(y in opt.text for y in [\"2022\", \"2023\", \"2024\"])]\n",
    "\n",
    "# Extract each month's data separately\n",
    "for month in target_months:\n",
    "    print(f\"Processing: {month}\")\n",
    "    select.select_by_visible_text(month)\n",
    "    time.sleep(2.5)  # Wait for table update\n",
    "\n",
    "    # Extract the UPI Apps tab HTML\n",
    "    tab_html = driver.find_element(By.ID, \"innerTabTwoJan22\").get_attribute(\"innerHTML\")\n",
    "    soup = BeautifulSoup(tab_html, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "\n",
    "    month_dfs = []\n",
    "\n",
    "    for table in tables:\n",
    "        try:\n",
    "            df = pd.read_html(str(table))[0]\n",
    "            df.insert(0, \"Month\", month)\n",
    "            month_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse a table for {month}: {e}\")\n",
    "\n",
    "    # Save each monthâ€™s data as a separate CSV\n",
    "    if month_dfs:\n",
    "        combined_df = pd.concat(month_dfs, ignore_index=True)\n",
    "        safe_month = month.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "        combined_df.to_csv(f\"{output_dir}/{safe_month}.csv\", index=False)\n",
    "        print(f\"Saved: {safe_month}.csv\")\n",
    "    else:\n",
    "        print(f\"No tables found for {month}\")\n",
    "\n",
    "# Quit the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d096d8c",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96664a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Correct way to rename the nan column to 'Month'\n",
    "\n",
    "folder = Path(folder_path)\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for files in folder.glob(\"*\"):\n",
    "    print(files)\n",
    "    df = pd.read_csv(files)\n",
    "    df= df.iloc[:, [0, 2, 11, 12]]\n",
    "    df.columns = df.iloc[1]\n",
    "    df = df.rename(columns={np.nan: 'Month'})\n",
    "    df = df.iloc[2:]\n",
    "    \n",
    "    all_dfs.append(df)\n",
    "    \n",
    "\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "#Script to clean data of a month wise upi apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Correct way to rename the nan column to 'Month'\n",
    "\n",
    "folder = Path(folder_paht)\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for files in folder.glob(\"*\"):\n",
    "    print(files)\n",
    "    df = pd.read_csv(files)\n",
    "    df = df.iloc[:, [0, 2, 3,4,6,8]]\n",
    "    df.columns = df.iloc[0]\n",
    "    df.columns.values[1] = \"UPI Remitter Banks\"\n",
    "    df.columns.values[0] = \"Month\"\n",
    "    df = df.iloc[1:]\n",
    "    \n",
    "    all_dfs.append(df)\n",
    "    \n",
    "\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "final_df.to_csv(\"Banks_Monthly.csv\", index=False)\n",
    "print(\"Csv printed\")\n",
    "\n",
    "#Script to clean data of a month wise upi banks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
